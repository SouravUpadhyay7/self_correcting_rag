import sys
import shutil
import os
from pathlib import Path

ROOT_DIR = Path(__file__).resolve().parents[2]
sys.path.append(str(ROOT_DIR))

import streamlit as st
from app.graph.workflow import build_graph
from app.ingestion.loader import load_pdf
from app.ingestion.splitter import split_docs
from app.ingestion.vectorstore import add_documents

app = build_graph()

# Page config
st.set_page_config(page_title="Self-Correcting RAG", page_icon="ğŸ§ ", layout="centered")

# Header
st.title("ğŸ§  Self-Correcting RAG Agent")
st.markdown("*Upload a PDF and ask questions â€” the agent self-corrects until it finds the best answer.*")
st.divider()

# Track which PDF is already indexed
if "indexed_file" not in st.session_state:
    st.session_state.indexed_file = None

# Upload section
st.subheader("ğŸ“„ Upload PDF")
uploaded_file = st.file_uploader("Choose a PDF file", type="pdf")

if uploaded_file:
    if st.session_state.indexed_file != uploaded_file.name:
        with st.spinner("ğŸ“¥ Indexing your PDF..."):
            with open("data/temp.pdf", "wb") as f:
                f.write(uploaded_file.read())
            docs = load_pdf("data/temp.pdf")
            split = split_docs(docs)
            add_documents(split)
            st.session_state.indexed_file = uploaded_file.name
        st.success(f"âœ… **{uploaded_file.name}** indexed successfully!")
    else:
        st.info(f"ğŸ“Œ **{uploaded_file.name}** is already indexed. Ask away!")

    # Clear index button
    if st.button("ğŸ—‘ï¸ Clear Index & Re-upload", type="secondary"):
        if os.path.exists("data/chroma_db"):
            shutil.rmtree("data/chroma_db")
        st.session_state.indexed_file = None
        st.success("âœ… Index cleared! Upload a new PDF.")
        st.rerun()

st.divider()

# Query section
st.subheader("ğŸ’¬ Ask a Question")
query = st.text_input("Type your question here...", placeholder="e.g. What are the main advantages of cloud computing?")

if st.button("ğŸš€ Run Agent", use_container_width=True):
    if not uploaded_file:
        st.warning("âš ï¸ Please upload a PDF first!")
    elif not query:
        st.warning("âš ï¸ Please enter a question!")
    else:
        with st.spinner("ğŸ¤” Agent is thinking and self-correcting..."):
            result = app.invoke({"question": query})

        st.divider()

        # Answer
        st.subheader("ğŸ’¡ Answer")
        st.success(result["answer"])

        # Confidence meter
        st.subheader("ğŸ“Š Confidence Score")
        confidence = result["confidence"]
        st.progress(confidence)
        if confidence >= 0.85:
            st.markdown(f"**{confidence:.2%}** ğŸŸ¢ High confidence")
        elif confidence >= 0.65:
            st.markdown(f"**{confidence:.2%}** ğŸŸ¡ Medium confidence")
        else:
            st.markdown(f"**{confidence:.2%}** ğŸ”´ Low confidence")

        # Scores breakdown
        st.subheader("ğŸ” Score Breakdown")
        col1, col2, col3 = st.columns(3)
        col1.metric("ğŸ“ Relevance", f"{result['relevance_score']:.2f}")
        col2.metric("âš“ Grounding", f"{result['grounding_score']:.2f}")
        col3.metric("âœ… Completeness", f"{result['completeness_score']:.2f}")

        # Self-correction attempts
        if result.get("failed_attempts", 0) > 0:
            st.subheader("ğŸ”„ Self-Correction Attempts")
            st.info(f"ğŸ” Agent reformulated the query **{result['failed_attempts']}** time(s)")
            if result.get("past_queries"):
                with st.expander("ğŸ“ See query history"):
                    for i, q in enumerate(result["past_queries"]):
                        st.markdown(f"**Attempt {i+1}:** {q}")

        # Retrieved documents
        with st.expander("ğŸ“š Retrieved Document Chunks"):
            for i, doc in enumerate(result["documents"]):
                st.markdown(f"**Chunk {i+1}:**")
                st.caption(doc)

        # Raw JSON
        with st.expander("ğŸ› ï¸ Raw JSON Output"):
            st.json(result)